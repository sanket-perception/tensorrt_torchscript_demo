{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c983e7-a4f2-4393-8a1d-030dbdf311e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eb001fd-ce6f-4946-bb2a-5234fe3c2640",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_image(img_path):\n",
    "    # transformations for the input data\n",
    "    transforms = Compose([\n",
    "        ToTensor(),\n",
    "        Resize(224),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # read input image\n",
    "    input_img = cv2.imread(img_path)\n",
    "    # do transformations\n",
    "    input_data = transforms(input_img)\n",
    "    batch_data = torch.unsqueeze(input_data, 0)\n",
    "    return batch_data\n",
    "\n",
    "def postprocess(output_data):\n",
    "    # get class names\n",
    "    with open(\"imagenet_classes.txt\") as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "    # calculate human-readable value by softmax\n",
    "    confidences = torch.nn.functional.softmax(output_data, dim=1)[0] * 100\n",
    "    # find top predicted classes\n",
    "    _, indices = torch.sort(output_data, descending=True)\n",
    "    i = 0\n",
    "    # print the top classes predicted by the model\n",
    "    while confidences[indices[0][i]] > 0.5:\n",
    "        class_idx = indices[0][i]\n",
    "        print(\n",
    "            \"class:\",\n",
    "            classes[class_idx],\n",
    "            \", confidence:\",\n",
    "            confidences[class_idx].item(),\n",
    "            \"%, index:\",\n",
    "            class_idx.item(),\n",
    "        )\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3358a98e-68c2-4bd5-bcec-6e3fd0e04c43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: cup , confidence: 94.98273468017578 %, index: 968\n",
      "class: espresso , confidence: 3.9471163749694824 %, index: 967\n",
      "class: coffee mug , confidence: 0.6194139122962952 %, index: 504\n"
     ]
    }
   ],
   "source": [
    "input = preprocess_image(\"turkish_coffee.jpg\").cuda()\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()\n",
    "model.cuda()\n",
    "output = model(input)\n",
    "\n",
    "postprocess(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "387ab26d-4642-494a-bd3a-0f2349baa471",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ONNX_FILE_PATH = 'resnet50.onnx'\n",
    "torch.onnx.export(model, input, ONNX_FILE_PATH, input_names=['input'],\n",
    "                  output_names=['output'], export_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16873f1e-5691-4344-aac8-0bcdf3c316e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import numpy as np\n",
    "import tensorrt as trt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466a2f6c",
   "metadata": {},
   "source": [
    "#### 1. Create Builder\n",
    "To create a builder, you must first create a logger. Then use the logger to create the builder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3eb1f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/28/2023-12:42:52] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage. See `CUDA_MODULE_LOADING` in https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars\n"
     ]
    }
   ],
   "source": [
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "builder = trt.Builder(TRT_LOGGER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3a0636",
   "metadata": {},
   "source": [
    "#### 2. Create Network\n",
    "After the builder has been created, the first step in optimizing a model is to create a network definition.\n",
    "The EXPLICIT_BATCH flag is required in order to import models using the ONNX parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72e99cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPLICIT_BATCH = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ac991a",
   "metadata": {},
   "source": [
    "#### 3. Import model using ONNX Parser\n",
    "Now, the network definition must be populated from the ONNX representation. You can create an ONNX parser to populate the network as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c858b64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = trt.OnnxParser(network, TRT_LOGGER)\n",
    "success = parser.parse_from_file(ONNX_FILE_PATH)\n",
    "for idx in range(parser.num_errors):\n",
    "    print(parser.get_error(idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f6343b",
   "metadata": {},
   "source": [
    "#### 4. Building an engine\n",
    "The next step is to create a build configuration specifying how TensorRT should optimize the model. This interface has many properties that you can set in order to control how TensorRT optimizes the network. One important property is the maximum workspace size. Layer implementations often require a temporary workspace, and this parameter limits the maximum size that any layer in the network can use. If insufficient workspace is provided, it is possible that TensorRT will not be able to find an implementation for a layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce55bcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = builder.create_builder_config()\n",
    "config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 22) # 1 MiB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2dc8f8",
   "metadata": {},
   "source": [
    "After the configuration has been specified, the engine can be built and serialized with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e8cebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_engine = builder.build_serialized_network(network, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4243997",
   "metadata": {},
   "source": [
    "It may be useful to save the engine to a file for future use. You can do that like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d91e04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sample.engine\", \"wb\") as f:\n",
    "    f.write(serialized_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da56c419",
   "metadata": {},
   "source": [
    "#### 5. Deserialize an Engine\n",
    "To perform inference, deserialize the engine using the Runtime interface. Like the builder, the runtime requires an instance of the logger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "762874ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = trt.Runtime(TRT_LOGGER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b470f8e",
   "metadata": {},
   "source": [
    "First load the engine from a file. Then deserialize the engine from a memory buffer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78e0417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sample.engine\", \"rb\") as f:\n",
    "    serialized_engine = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42324492",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = runtime.deserialize_cuda_engine(serialized_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148c44d1",
   "metadata": {},
   "source": [
    "#### 6. Performing Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd66913",
   "metadata": {},
   "source": [
    "The engine holds the optimized model, but to perform inference requires additional state for intermediate activations. An engine can have multiple execution contexts, allowing one set of weights to be used for multiple overlapping inference tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54a99caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/28/2023-12:43:10] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage. See `CUDA_MODULE_LOADING` in https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars\n"
     ]
    }
   ],
   "source": [
    "context = engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5465dbb6",
   "metadata": {},
   "source": [
    "Allocate some host and device buffers for inputs and outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0279ae03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4154/2233168342.py:2: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  h_input = cuda.pagelocked_empty(trt.volume(engine.get_binding_shape(0)), dtype=np.float32)\n",
      "/tmp/ipykernel_4154/2233168342.py:3: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  h_output = cuda.pagelocked_empty(trt.volume(engine.get_binding_shape(1)), dtype=np.float32)\n"
     ]
    }
   ],
   "source": [
    "# Determine dimensions and create page-locked memory buffers (i.e. won't be swapped to disk) to hold host inputs/outputs.\n",
    "h_input = cuda.pagelocked_empty(trt.volume(engine.get_binding_shape(0)), dtype=np.float32)\n",
    "h_output = cuda.pagelocked_empty(trt.volume(engine.get_binding_shape(1)), dtype=np.float32)\n",
    "# Allocate device memory for inputs and outputs.\n",
    "d_input = cuda.mem_alloc(h_input.nbytes)\n",
    "d_output = cuda.mem_alloc(h_output.nbytes)\n",
    "# Create a stream in which to copy inputs/outputs and run inference.\n",
    "stream = cuda.Stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d339b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "host_input = np.array(preprocess_image(\"turkish_coffee.jpg\").numpy(), dtype=np.float32, order='C')\n",
    "# Transfer input data to the GPU.\n",
    "cuda.memcpy_htod_async(d_input, host_input, stream)\n",
    "# Run inference.\n",
    "context. execute_async_v2(bindings=[int(d_input), int(d_output)], stream_handle=stream.handle)\n",
    "# Transfer predictions back from the GPU.\n",
    "cuda.memcpy_dtoh_async(h_output, d_output, stream)\n",
    "# Synchronize the stream\n",
    "stream.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf881178",
   "metadata": {},
   "source": [
    "Create some space to store intermediate activation values. Since the engine holds the network definition and trained parameters, additional space is necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4719b676-34a1-4107-95c3-338e619c99ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_data = torch.Tensor(h_output).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dfa64093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: cup , confidence: 94.98615264892578 %, index: 968\n",
      "class: espresso , confidence: 3.944007635116577 %, index: 967\n",
      "class: coffee mug , confidence: 0.6195164918899536 %, index: 504\n"
     ]
    }
   ],
   "source": [
    "postprocess(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e42996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('bevfusion')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd2e805bf45cfce0ee59caeff624ebf2dd294551239d1fbf11f6751485705e2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
